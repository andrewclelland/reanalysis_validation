{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e03c9d8a-e630-4967-bb7f-4580721bbfcc",
   "metadata": {},
   "source": [
    "# Extract reanalysis data at point - station"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d5c5e5-44ff-48c3-8006-d512a2de95ac",
   "metadata": {},
   "source": [
    "Code correct as of Summer 2023.\n",
    "\n",
    "Extract data interpolated at a specified point from the daily ERA-Interim/ERA5/ERA5-Land data held on the bas_climate group workspace. The currently available daily data (all means unless otherwise stated) are:\n",
    "\n",
    "* MSLP (msl) or surface pressure (sp - ERA5-land)\n",
    "* 2m air temperature -- daily mean (t2m/mean_t2m), maximum (mx2t/max_t2m) and minimum (mn2t/min_t2m)\n",
    "* soil temperature on 4 levels (stl1, stl2, stl3, stl4)\n",
    "* 10m wind field components (u10, v10)\n",
    "* 2m dew point temperature (d2m)\n",
    "* daily total precipitation (tp)\n",
    "* snow depth (sd) and snow density (rsn)\n",
    "\n",
    "The variable codes shown in brackets above are the names of the directories in which the data for that variable are held on the bas_climate gws.\n",
    "\n",
    "* ERA-Interim data are available January 1979 to August 2019\n",
    "* ERA5 data are available January 1940 to present\n",
    "* ERA5-Land data are available January 1950 to present"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabd5c1e-e4ab-408b-8569-47975610e093",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Inputs - always run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa86ba15-71a0-439a-b06f-99a8e5cb756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import iris\n",
    "import iris.pandas\n",
    "from iris.time import PartialDateTime\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set the envionment variable HDF5_USE_FILE_LOCKING to avoid potential hangs\n",
    "# This means that the netCDF library ignores advisory exclusive locks on ERA5 data files, otherwise a hang may occur\n",
    "os.environ['HDF5_USE_FILE_LOCKING'] = 'FALSE'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afd6c95-756e-46ba-8f97-3573b85118f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960f8d88-0c80-4861-921d-99c1b56a4d65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the variables to read - see list of variable codes above\n",
    "# NOTE - variablesdaily does NOT include d2m because 'TTTR' does not include a d2m value\n",
    "\n",
    "# ERA-Interim\n",
    "#variables = ['msl', 'd2m', 't2m', 'u10', 'v10', 'mx2t', 'mn2t', 'tp']\n",
    "#variablesdaily = ['SD', 'RSN', 'T2', 'TP', 't2max', 't2min', 'MSL', 'u10', 'v10']\n",
    "\n",
    "# ERA5\n",
    "variables = ['msl', 'd2m', 't2m', 'u10', 'v10', 'mx2t', 'mn2t', 'tp']\n",
    "variablesdaily = ['stl1', 'stl2', 'stl3', 'stl4', 'msl', 'sd', 'rsn', 't2m', 'mx2t', 'mn2t', 'tp', 'u10', 'v10']\n",
    "\n",
    "# ERA5-Land\n",
    "#variables = ['sp', 'd2m', 'mean_t2m', 'u10', 'v10', 'max_t2m', 'min_t2m', 'tp']\n",
    "#variablesdaily = ['stl1', 'stl2', 'stl3', 'stl4', 'sp', 'sd', 'rsn', 'd2m', 'mean_t2m', 'max_t2m', 'min_t2m', 'tp', 'u10', 'v10']\n",
    "\n",
    "# define station WMO number\n",
    "station = 23678\n",
    "\n",
    "# the point at which to extract the data - use met station coordinates\n",
    "# this will interpolate the coarse resolution data\n",
    "# positive for degrees North/East - negative for degrees South/West\n",
    "lat = 63.15\n",
    "lon = 87.95\n",
    "\n",
    "# the range of dates over which to extract the data - year, month, day\n",
    "start_year, start_month, start_day = 1979, 1, 1\n",
    "end_year, end_month, end_day = 2019, 8, 31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778ae4cc-4b2b-4d1c-b079-6ac0fa5875c8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Read and extract data - sub-daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b90a847-5444-465f-bf0b-b795014869a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERA-Interim is 6-hourly; ERA5 and ERA5-Land are 3-hourly\n",
    "# the location of the data\n",
    "hourly_data_dir = '/gws/nopw/j04/bas_climate/users/clelland/era5/58.0N-64.5N_82.0E-95.5E/3-hourly' # <-- CHANGE AS NECESSARY\n",
    "\n",
    "values = iris.cube.CubeList()\n",
    "\n",
    "for i, variable in enumerate(variables):\n",
    "    print('At {}, reading data for {}'.format(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), variable))\n",
    "\n",
    "    files = sorted(glob('{}/{}/*.nc'.format(hourly_data_dir, variable)))\n",
    "    var_values = iris.cube.CubeList()\n",
    "\n",
    "    for file in tqdm(files):\n",
    "        # read the data\n",
    "        cube = iris.load_cube(file)\n",
    "\n",
    "        # extract the required date range\n",
    "        # note: if the date range does not intersect the range of data read, the resulting cube will be None\n",
    "        time_coord_name = cube.coord(axis='t').name()\n",
    "        start_date_pdt = PartialDateTime(start_year, start_month, start_day)\n",
    "        start_con = iris.Constraint(coord_values={time_coord_name:lambda cell: start_date_pdt <= cell.point})\n",
    "        end_date_pdt = PartialDateTime(end_year, end_month, end_day)\n",
    "        end_con = iris.Constraint(coord_values={time_coord_name:lambda cell: end_date_pdt >= cell.point})\n",
    "        cube = cube.extract(start_con & end_con)\n",
    "\n",
    "        if cube is not None:\n",
    "            # interpolate the value at the requested point\n",
    "            var_values.append(cube.interpolate([(cube.coord(axis='x'), lon), (cube.coord(axis='y'), lat)], iris.analysis.Linear(extrapolation_mode='error')))\n",
    "\n",
    "    # concatenate the interpolated cubes into a single cube and store it\n",
    "    values.append(var_values.concatenate_cube())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000e0b0a-5d73-45c8-8803-b57d98ad5d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, var_values in enumerate(values):\n",
    "    # copy the cube and set the \"time\" part of its time coordinate to 12:00 so that they all agree\n",
    "    # this is not the case in the daily data files as the means of hourly means are 24-hour means running from 00:00 to 24:00,\n",
    "    # but the means of instantaneous data are actually 23-hour means running from 00:00 to 23:00\n",
    "    var_values_for_df = var_values.copy()\n",
    "    time_coord = var_values_for_df.coord(axis='t') # <-- CHECK THIS: could be 'time'\n",
    "    time_coord.points = np.array([time_coord.units.date2num(tp.replace(minute=0)) for tp in time_coord.units.num2date(time_coord.points)])\n",
    "\n",
    "    # create or add the values to a DataFrame\n",
    "    if i == 0:\n",
    "        df = iris.pandas.as_series(var_values_for_df).to_frame(name=var_values_for_df.var_name)\n",
    "    else:\n",
    "        df = pd.concat([df, iris.pandas.as_series(var_values_for_df).to_frame(name=var_values_for_df.var_name)], axis=1)\n",
    "\n",
    "df.index.rename(time_coord.name(), inplace=True)\n",
    "\n",
    "# save station pandas dataframe to folder in directory\n",
    "filepath = Path(f'/home/users/clelland/era5/stations_pandas_files/{station}/{station}e53h.csv') # <-- CHANGE AS NECESSARY\n",
    "df.to_csv(filepath, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53590ea-16f8-40d2-9f0a-f8475a21b263",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Read and extract data - daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a13ef2f-4d6f-4217-bdc0-4f6267ff7fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the location of the daily data\n",
    "daily_data_dir = '/gws/nopw/j04/bas_climate/users/clelland/era5/58.0N-64.5N_82.0E-95.5E/daily' # <-- CHANGE AS NECESSARY\n",
    "\n",
    "valuesdaily = iris.cube.CubeList()\n",
    "\n",
    "for i, variable in enumerate(variablesdaily):\n",
    "    print('At {}, reading data for {}'.format(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), variable))\n",
    "\n",
    "    files = sorted(glob('{}/{}/*.nc'.format(daily_data_dir, variable)))\n",
    "    var_values = iris.cube.CubeList()\n",
    "\n",
    "    for file in tqdm(files):\n",
    "        # read the data\n",
    "        cube = iris.load_cube(file)\n",
    "\n",
    "        # extract the required date range\n",
    "        # note: if the date range does not intersect the range of data read, the resulting cube will be None\n",
    "        time_coord_name = cube.coord(axis='t').name()\n",
    "        start_date_pdt = PartialDateTime(start_year, start_month, start_day)\n",
    "        start_con = iris.Constraint(coord_values={time_coord_name:lambda cell: start_date_pdt <= cell.point})\n",
    "        end_date_pdt = PartialDateTime(end_year, end_month, end_day)\n",
    "        end_con = iris.Constraint(coord_values={time_coord_name:lambda cell: end_date_pdt >= cell.point})\n",
    "        cube = cube.extract(start_con & end_con)\n",
    "\n",
    "        if cube is not None:\n",
    "            # interpolate the value at the requested point\n",
    "            var_values.append(cube.interpolate([(cube.coord(axis='x'), lon), (cube.coord(axis='y'), lat)], iris.analysis.Linear(extrapolation_mode='error')))\n",
    "\n",
    "    # concatenate the interpolated cubes into a single cube and store it\n",
    "    valuesdaily.append(var_values.concatenate_cube())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2a82b4-57d9-4418-95ab-93aa51a1eee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, var_values in enumerate(valuesdaily):\n",
    "    # copy the cube and set the \"time\" part of its time coordinate to 12:00 so that they all agree\n",
    "    # this is not the case in the daily data files as the means of hourly means are 24-hour means running from 00:00 to 24:00,\n",
    "    # but the means of instantaneous data are actually 23-hour means running from 00:00 to 23:00\n",
    "    var_values_for_df = var_values.copy()\n",
    "    time_coord = var_values_for_df.coord(axis='t') # <-- CHECK THIS: could be 'time'\n",
    "    time_coord.points = np.array([time_coord.units.date2num(tp.replace(hour=12, minute=0)) for tp in time_coord.units.num2date(time_coord.points)])\n",
    "\n",
    "    # create or add the values to a DataFrame\n",
    "    if i == 0:\n",
    "        dfdaily = iris.pandas.as_series(var_values_for_df).to_frame(name=var_values_for_df.var_name)\n",
    "    else:\n",
    "        dfdaily = pd.concat([dfdaily, iris.pandas.as_series(var_values_for_df).to_frame(name=var_values_for_df.var_name)], axis=1)\n",
    "\n",
    "dfdaily.index.rename(time_coord.name(), inplace=True)\n",
    "\n",
    "# save station pandas dataframe to folder in home directory\n",
    "filepath = Path(f'/home/users/clelland/era5/stations_pandas_files/{station}/{station}e5daily.csv') # <-- CHANGE AS NECESSARY\n",
    "dfdaily.to_csv(filepath, sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
